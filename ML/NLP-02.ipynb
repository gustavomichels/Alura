{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "443faf37-bca6-4cae-bae0-ce0202fde38a",
   "metadata": {},
   "source": [
    "# <font color='#5581A5'> Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac80e7ae-dd3c-48da-8c92-d68b9da29bda",
   "metadata": {},
   "source": [
    "<font color=#5581A5> **The objective of this project is twofold: to delve into the study of natural language processing (NLP) while advancing further in the exploration of Jupyter Notebook and Python.**\n",
    "\n",
    "Several practices will be employed in this study:\n",
    "\n",
    "1- Below certain commands, there will be a summary of their meanings.\n",
    "\n",
    "2- All text will be written in English.\n",
    "\n",
    "3- The data has been extracted from exercises on the Alura platform."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b18be3c5-fc44-4394-95db-a8fa04d7d15b",
   "metadata": {},
   "source": [
    "# About\n",
    "\n",
    "We will build a Portuguese spell checker using Python and applying NLP techniques.\n",
    "\n",
    "Additionally, we will discuss various topics such as machine-human communication, and we will see that this interaction is not direct. Instead, it involves an intermediary, which is Natural Language Processing (NLP).\n",
    "\n",
    "NLP has a wide range of applications, including personal assistants like Google Assistant, Apple's Siri, Alexa, and others.\n",
    "\n",
    "We will also perform sentiment analysis, which allows us to evaluate a person's opinion about a movie as positive or negative. Furthermore, translation tools and search engines like Google heavily utilize these resources, as will the spell checker we will build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8907fda-3b8b-4412-be75-80ab693aa4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "27d2a27a-573c-4e98-bd77-26cc8b1a3f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "imagem \n",
      "\n",
      "Temos a seguinte classe que representa um usuário no nosso sistema:\n",
      "\n",
      "java\n",
      "\n",
      "Para salvar um novo usuário, várias validações são feitas, como por exemplo: Ver se o nome só contém letras, [**o CPF só números**] e ver se o usuário possui no mínimo 18 anos. Veja o método que faz essa validação:\n",
      "\n",
      "java \n",
      "\n",
      "Suponha agora que eu tenha outra classe, a classe `Produto`, que contém um atributo nome e eu quero fazer a mesma validação que fiz para o nome do usuário: Ver se só contém letras. E aí? Vou\n"
     ]
    }
   ],
   "source": [
    "# Opening file\n",
    "\n",
    "with open(\"Dados/NLP/Corretor/corretor-master/artigos.txt\", 'r', encoding='utf-8') as f:\n",
    "    articles = f.read()\n",
    "\n",
    "print(articles[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "289b6b0d-36ea-4c76-9e51-6bdacd062a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['imagem', 'Temos', 'a', 'seguinte', 'classe', 'que', 'representa', 'um', 'usuário', 'no', 'nosso', 'sistema', ':', 'java', 'Para', 'salvar', 'u']\n"
     ]
    }
   ],
   "source": [
    "# Tokenize\n",
    "\n",
    "# nltk.download('punkt')\n",
    "\n",
    "separate_words_text = nltk.tokenize.word_tokenize(articles[:100])\n",
    "print(separate_words_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d9ad61-b47f-4b44-b1c2-89f2d0f9e322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagem',\n",
       " 'Temos',\n",
       " 'a',\n",
       " 'seguinte',\n",
       " 'classe',\n",
       " 'que',\n",
       " 'representa',\n",
       " 'um',\n",
       " 'usuário',\n",
       " 'no',\n",
       " 'nosso',\n",
       " 'sistema',\n",
       " 'java',\n",
       " 'Para',\n",
       " 'salvar',\n",
       " 'u']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating function to separate words from punctuation\n",
    "\n",
    "\n",
    "def separate_words(list_tokens):\n",
    "    list_words = []\n",
    "    for token in list_tokens:\n",
    "        if token.isalpha():\n",
    "            list_words.append(token)\n",
    "    return list_words\n",
    "\n",
    "# testing\n",
    "\n",
    "separate_words(separate_words_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e4607943-a055-44f4-96d8-01288fb5a1bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "403104"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying on our corpous\n",
    "\n",
    "list_tokens = nltk.tokenize.word_tokenize(articles)\n",
    "list_words = separate_words(list_tokens)\n",
    "len(list_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e9fc15d-c25d-4e4f-8070-c8f3ebafdb5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['imagem',\n",
       " 'temos',\n",
       " 'a',\n",
       " 'seguinte',\n",
       " 'classe',\n",
       " 'que',\n",
       " 'representa',\n",
       " 'um',\n",
       " 'usuário',\n",
       " 'no',\n",
       " 'nosso',\n",
       " 'sistema',\n",
       " ':',\n",
       " 'java',\n",
       " 'para',\n",
       " 'salvar',\n",
       " 'u']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying normalize\n",
    "\n",
    "def normalize_text(list_words):\n",
    "    list_normalized = []\n",
    "    for word in list_words:\n",
    "        list_normalized.append(word.lower())\n",
    "    return list_normalized\n",
    "\n",
    "# Testing\n",
    "\n",
    "normalize_text(separate_words_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "68623c82-f895-4492-9142-7d882a49aed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18465"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying normalization on our article\n",
    "\n",
    "list_normalized = normalize_text(list_words)\n",
    "\n",
    "# Removing same words\n",
    "\n",
    "list_words_treated = set(list_normalized)\n",
    "\n",
    "# Checking result\n",
    "\n",
    "len(list_words_treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b9b10291-f193-4cca-a82c-b42efc2bbeb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lógica\n"
     ]
    }
   ],
   "source": [
    "# Creating variables to store frequency and the number of words in our list\n",
    "\n",
    "frequency = nltk.FreqDist(list_normalized)\n",
    "total_words = len(list_normalized)\n",
    "\n",
    "# Creating function to generate words\n",
    "\n",
    "def generate_words(word):\n",
    "    slices = []\n",
    "    for i in range(len(word) + 1):\n",
    "        slices.append((word[:i], word[i:]))\n",
    "    \n",
    "    generated_words = insert_words(slices)\n",
    "    return generated_words\n",
    "\n",
    "# Creating function to insert letters between words\n",
    "\n",
    "def insert_words(slices):\n",
    "    new_words = []\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "\n",
    "    for L, R in slices:  \n",
    "        for letter in letters:\n",
    "            new_words.append(L + letter + R)\n",
    "    \n",
    "    return new_words\n",
    "\n",
    "# Creating spell checker function\n",
    "\n",
    "def spell_checker(word):\n",
    "    generated_words = generate_words(word)\n",
    "    right_word = max(generated_words, key=probability)\n",
    "    \n",
    "    return right_word\n",
    "\n",
    "# Function to calculate the probability to be the right word\n",
    "\n",
    "def probability(word):\n",
    "    return frequency[word] / total_words\n",
    "\n",
    "# Example usage\n",
    "tested_word = 'lgica'\n",
    "print(spell_checker(tested_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bfe43792-e9a5-4842-ae2d-db01500b252c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('podemos', 'pyodemos'), ('esse', 'esje'), ('já', 'jrá'), ('nosso', 'nossov'), ('são', 'sãêo'), ('dos', 'dosa'), ('muito', 'muifo'), ('imagem', 'iômagem'), ('sua', 'ósua'), ('também', 'tambéùm'), ('ele', 'eme'), ('fazer', 'èazer'), ('temos', 'temfs'), ('essa', 'eàssa'), ('quando', 'quaôdo'), ('vamos', 'vamvos'), ('sobre', 'hsobre'), ('java', 'sjava'), ('das', 'daõs'), ('agora', 'agorah'), ('está', 'eòtá'), ('cada', 'céda'), ('mesmo', 'zmesmo'), ('nos', 'noâ'), ('forma', 'fobma'), ('seja', 'sejéa'), ('então', 'enêão'), ('criar', 'èriar'), ('código', 'cóeigo'), ('caso', 'casío'), ('exemplo', 'áexemplo'), ('tem', 'tĩem'), ('usuário', 'usuárôio'), ('dados', 'dfados'), ('python', 'pgthon'), ('nossa', 'nossah'), ('além', 'alémè'), ('assim', 'asõim'), ('ter', 'teb'), ('até', 'atĩ'), ('bem', 'âem'), ('design', 'desigen'), ('trabalho', 'trabalàho'), ('foi', 'foo'), ('apenas', 'apenaũ'), ('empresa', 'empresà'), ('valor', 'valíor'), ('será', 'serr'), ('entre', 'entke'), ('método', 'méqodo'), ('precisamos', 'precisamops'), ('ainda', 'ainàa'), ('vai', 'van'), ('conteúdo', 'ûconteúdo'), ('seus', 'çeus'), ('eu', 'eû'), ('todos', 'todtos'), ('tempo', 'temeo'), ('sempre', 'semre'), ('qual', 'quakl'), ('ela', 'elaá'), ('só', 'síó'), ('utilizar', 'utiqizar'), ('projeto', 'prhojeto'), ('site', 'siàe'), ('sem', 'seém'), ('pelo', 'peln'), ('alura', 'aléra'), ('dia', 'tdia'), ('tudo', 'tuúo'), ('podemos', 'kpodemos'), ('esse', 'eẽsse'), ('já', 'jé'), ('nosso', 'nçosso'), ('são', 'sãô'), ('dos', 'odos'), ('muito', 'tuito'), ('imagem', 'imõgem'), ('sua', 'siua'), ('também', 'tamvbém'), ('ele', 'elpe'), ('fazer', 'façzer'), ('temos', 'teos'), ('essa', 'eũsa'), ('quando', 'quaìdo'), ('vamos', 'vjmos'), ('sobre', 'sxobre'), ('java', 'jkva'), ('das', 'dms'), ('agora', 'agtora'), ('está', 'esútá'), ('cada', 'cava'), ('mesmo', 'medmo'), ('nos', 'ános'), ('forma', 'forûa'), ('seja', 'smeja'), ('então', 'enjtão'), ('criar', 'criôar'), ('código', 'cóàigo'), ('caso', 'èaso'), ('exemplo', 'exbemplo'), ('tem', 'túem'), ('usuário', 'usuárin'), ('dados', 'daáos'), ('python', 'pythoçn'), ('nossa', 'nossk'), ('além', 'âlém'), ('assim', 'aóssim'), ('ter', 'tãer'), ('até', 'vté'), ('bem', 'búm'), ('design', 'íesign'), ('trabalho', 'trabèalho'), ('foi', 'kfoi'), ('apenas', 'aapenas'), ('empresa', 'pmpresa'), ('valor', 'valoqr'), ('será', 'sçerá'), ('entre', 'entró'), ('método', 'nétodo'), ('precisamos', 'prefcisamos'), ('ainda', 'sainda'), ('vai', 'uai'), ('conteúdo', 'cĩonteúdo'), ('seus', 'sâus'), ('eu', 'ìeu'), ('todos', 'todás'), ('tempo', 'utempo'), ('sempre', 'sempce'), ('qual', 'fual'), ('ela', 'elal'), ('só', 'skó'), ('utilizar', 'utilĩzar'), ('projeto', 'proójeto'), ('site', 'isite'), ('sem', 'secm'), ('pelo', 'pẽlo'), ('alura', 'aluéa'), ('dia', 'dil'), ('tudo', 'tudy'), ('ela', 'qelay'), ('só', 'sód'), ('utilizar', 'dtilizacr'), ('projeto', 'bprojõto'), ('site', 'ysiteo'), ('sem', 'sõêm'), ('pelo', 'peàli'), ('alura', 'asuraó'), ('dia', 'deiìa'), ('tudo', 'tuĩdoì'), ('ela', 'eúaa'), ('só', 'ró'), ('utilizar', 'utilizẽaçr'), ('projeto', 'prêjetó'), ('site', 'sqiqte'), ('sem', 'sũexm'), ('pelo', 'pçlxo'), ('alura', 'uluraa'), ('dia', 'dĩaz'), ('tudo', 'kzudo'), ('corretor', 'correptor'), ('tática', 'trtica'), ('empoderamento', 'ewpoderamento'), ('linux', 'lifux'), ('cachorro', 'cachoçro'), ('gato', 'îgato'), ('cavalo', 'cakvalo'), ('relógio', 'relógiuo'), ('canela', 'canelac'), ('tênis', 'tênisy'), ('ansiosa', 'anciosa'), ('ansiosa', 'ancciosa'), ('ansiosa', 'ansioa'), ('empoderamento', 'empoderamento'), ('asterisco', 'asterístico'), ('gratuito', 'gratuíto'), ('entretido', 'entertido'), ('ritmo', 'ritimo'), ('idiota', 'indiota'), ('tomara', 'tomare'), ('seja', 'seje'), ('prevalecer', 'provalecer'), ('esteja', 'esteje'), ('mendigo', 'mindigo'), ('cérebro', 'célebro'), ('perturbar', 'pertubar')]\n"
     ]
    }
   ],
   "source": [
    "# Creating testing scenario to evaluate how accurate the model is\n",
    "\n",
    "def data_test_creation(file_name):\n",
    "    list_test_words = []\n",
    "    with open(file_name, 'r', encoding='utf-8') as f:\n",
    "        for line in f:\n",
    "            parts = line.split()\n",
    "            if len(parts) >= 2:\n",
    "                right_word = parts[0]\n",
    "                wrong_word = parts[1]\n",
    "                list_test_words.append((right_word, wrong_word))\n",
    "    return list_test_words\n",
    "\n",
    "# Example usage\n",
    "test_list = data_test_creation('Dados/NLP/Corretor/corretor-master/palavras.txt')\n",
    "print(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b250b89a-6cd4-4ac5-8b45-943edb61bc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.08 % of 186 words\n"
     ]
    }
   ],
   "source": [
    "# Creating evaluator function\n",
    "\n",
    "def evaluate(test):\n",
    "    total_words = len(test)\n",
    "    hit = 0\n",
    "    for right, wrong in test:\n",
    "        corrected_word = spell_checker(wrong)\n",
    "        if corrected_word == right:\n",
    "            hit += 1\n",
    "    hit_ratio = hit/total_words\n",
    "    print(f'{round((hit_ratio * 100),2)} % of {total_words} words')\n",
    "\n",
    "evaluate(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d006170c-404d-4cd9-9c7f-b0dc6ba5ec2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.4 % of 186 words\n"
     ]
    }
   ],
   "source": [
    "# Creating function to delete characters if someone type more letters\n",
    "\n",
    "def delete_character(slices):\n",
    "    new_words = []\n",
    "\n",
    "    for L, R in slices:  \n",
    "        new_words.append(L + R[1:])\n",
    "    \n",
    "    return new_words\n",
    "\n",
    "# Concatenating the lists of letter deletion and insertion cases\n",
    "\n",
    "def generate_words(word):\n",
    "    slices = []\n",
    "    for i in range(len(word) + 1):\n",
    "        slices.append((word[:i], word[i:]))\n",
    "    \n",
    "    generated_words = insert_words(slices)\n",
    "    generated_words += delete_character(slices)\n",
    "    \n",
    "    return generated_words\n",
    "\n",
    "evaluate(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "22cf44ea-76c3-43c1-8af5-1f5279e6de65",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34 % of 186 words\n"
     ]
    }
   ],
   "source": [
    "# Creating function if someone type a wrong letter (not inserting or missing)\n",
    "\n",
    "def change_character(slices):\n",
    "    new_words = []\n",
    "    letters = 'abcdefghijklmnopqrstuvwxyzàáâãèéêìíîòóôõùúûç'\n",
    "\n",
    "    for L, R in slices:  \n",
    "        for letter in letters:\n",
    "            new_words.append(L + letter + R[1:])\n",
    "    \n",
    "    return new_words\n",
    "\n",
    "# Changing generate words to include change letter function\n",
    "\n",
    "def generate_words(word):\n",
    "    slices = []\n",
    "    for i in range(len(word) + 1):\n",
    "        slices.append((word[:i], word[i:]))\n",
    "    \n",
    "    generated_words = insert_words(slices)\n",
    "    generated_words += delete_character(slices)\n",
    "    generated_words += change_character(slices)\n",
    "    \n",
    "    return generated_words\n",
    "\n",
    "evaluate(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "97207cc0-85f6-419a-b17e-1dd1f7256aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34 % of 186 words\n"
     ]
    }
   ],
   "source": [
    "# Creating function if someone invert words\n",
    "\n",
    "def invert_character(slices):\n",
    "    new_words = []\n",
    "\n",
    "    for L, R in slices:  \n",
    "        if len(R) > 1:\n",
    "            new_words.append(L + R[1] + R[0] + R[2:])\n",
    "    \n",
    "    return new_words\n",
    "\n",
    "# Changing generate words to include invert character function\n",
    "\n",
    "def generate_words(word):\n",
    "    slices = []\n",
    "    for i in range(len(word) + 1):\n",
    "        slices.append((word[:i], word[i:]))\n",
    "    \n",
    "    generated_words = insert_words(slices)\n",
    "    generated_words += delete_character(slices)\n",
    "    generated_words += change_character(slices)\n",
    "    generated_words += invert_character(slices)\n",
    "    \n",
    "    return generated_words\n",
    "\n",
    "evaluate(test_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a347866d-296b-47ed-9f32-1bc55ae094ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76.34 % of 186 words - unknown 16.13 % \n"
     ]
    }
   ],
   "source": [
    "# Now we have a problem in our spell checker, some words are unknown, and we are limited to our test list of words, lets check how many words are unknown\n",
    "\n",
    "def evaluate(test, vocabulary):\n",
    "    total_words = len(test)\n",
    "    hit = 0\n",
    "    unknown = 0\n",
    "    for right, wrong in test:\n",
    "        corrected_word = spell_checker(wrong)\n",
    "        unknown += (corrected_word not in vocabulary)\n",
    "        if corrected_word == right:\n",
    "            hit += 1\n",
    "    hit_ratio = hit/total_words\n",
    "    unknown_ratio = unknown/total_words\n",
    "    \n",
    "    print(f'{round((hit_ratio * 100),2)} % of {total_words} words - unknown {round((unknown_ratio * 100),2)} % ')\n",
    "\n",
    "evaluate(test_list, list_words_treated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "de08656a-17e6-4092-95ca-3218a62a5ffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'lógica'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Another problem is if the person inserts more than one word wrong, lets fix it\n",
    "\n",
    "def generated_words_better(g_words):\n",
    "    new_words = []\n",
    "    for word in g_words:\n",
    "        new_words += generate_words(word)\n",
    "    return new_words\n",
    "\n",
    "# Creating new spell checker\n",
    "\n",
    "def spell_checker_new(word):\n",
    "    generated_words = generate_words(word)\n",
    "    better_words = generated_words_better(generated_words)\n",
    "    all_words = set(generated_words + better_words)\n",
    "    candidates = [word]\n",
    "    for word in all_words:\n",
    "        if word in list_words_treated:\n",
    "            candidates.append(word)\n",
    "    right_word = max(candidates, key=probability)\n",
    "    return right_word\n",
    "\n",
    "tested_word = 'lóiigica'\n",
    "spell_checker_new(tested_word)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
